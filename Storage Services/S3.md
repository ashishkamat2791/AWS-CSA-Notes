# S3 (Simple Storage Service):

* Amazon Simple Storage Service (Amazon S3), provides developers and IT teams with secure, durable, highly-scalable cloud storage. 
* Amazon S3 is easy to use object storage, with a simple web service interface to store and retrieve any amount of data from anywhere on the web. 


* Object based storage only for files, can not install OS or applications
* Data is spread across multiple devices and multiple facilities
* Can loose 2 facilities and still have access to your files
* Files can be between 1 byte and 5TB, and has no storage limit
* Files are stored flatly in buckets, Folders don't really exist, but are part of the file name
* S3 bucket names have a universal name-space, meaning each bucket name must be globally unique
* S3 Stores data in alphabetical order (lexigraphical order)
* S3 URL structures are region/amazon.aws.com/bucketname (https://s3-eu-west-1.amazonaws.com/myawesomebucket)
* **Read after write consistency for PUTS of new objects** (As soon as you write an object, it is immediately available)
* **Eventual consistency for overwrite PUTS and DELETES** (Updating or deleting an object could take time to propagate)
* S3 is basically a key value store and consists of the following:
    *  Key - Name of the object
    *  Value - Data made up of bytes
    *  Version ID (important for versioning)
    *  Meta-data - Data about what you are storing
    *  ACLs - Permissions for stored objects

* Amazon guarantees **99.99%** availability for the S3 platform
* Amazon guarantees **99.999999999%** durability for S3 information (11 x 9's)
* Tiered storage, and life-cycle management available
* Versioning is available but must be enabled. It is off by default
* Offers encryption, and allows you to secure the data using ACLs
* S3 charges for 
    * storage, 
    * requests, 
    * data transfer

* Bucket names must be all lowercase, however in US-Standard if creating with the CLI tool, it will allow capital letters
* The transfers tab shows uploads, downloads, permission changes, storage class changes, etc..
* When you upload a file to S3, by default it is set private
* You can transfer files up to 5GB using PUT requests
* You can setup access control to control your buckets access by using bucket policies or ACLs
Change the storage class under the Properties tab when an object is selected
* S3 buckets can be configured to create access logs which logs all requests to the S3 bucket
* S3 Events include SNS, or SQS events or Lambda functions. Lambda is location specific, not available in South Korea
*   All storage tiers have SSL support, millisecond first byte latency, and support life-cycle management policies.


## Storage Tiers:

### Standard S3:
* Stored redundantly across multiple devices in multiple facilities
* Designed to sustain the loss of 2 facilities concurrently
* 11-9's durability, 99.99% availability

### S3-IA (Infrequently Accessed):
* For data that is accessed less frequently, but requires rapid access when needed
* Lower fee than S3, but you are charged a retrieval fee
* Also designed to sustain the loss of 2 facilities concurrently
* 11-9's durability, 99.99% availability

### Reduced Redundancy Storage (RSS):
* Use for data such as thumbnails or data that could be regenerated
* Costs less than Standard S3
* Designed to provide 99.99% durability and 99.99% availability of objects over a year
* Designed to sustain the loss of a single facility

### Glacier:
* Very cheap, Stores data for as little as $0.01 per gigabyte, per month
* Optimized for data that is infrequently accessed. Used for archival only
* It takes 3-5 hours to restore access to files from Glacier

## Versioning and Cross-Region Replication (CRR):
* Versioning must be enabled in order to take advantage of Cross-Region Replication
* Versioning resides under Cross Region Replication tab
* Once Versioning is turned on, it can not be turned off, it can only be suspended
* If you truly wanted versioning off, you would have to create a new bucket and move your objects
* When versioning is enabled, you will see a slider tab at the top of the console that will enable you to hide/show all versions of files in the bucket
* If a file is deleted for example, you need to slide this tab to show in order to see previous versions of the file
* With versioning enabled, if you delete a file, S3 creates a **delete marker** for that file, which tells the console to not display the file any longer
* In order to restore a deleted file you simply delete the delete marker file, and the file will then be displayed again in the bucket
* To move back to a previous version of a file including a deleted file, simply delete the newest version of the file or the delete marker, and the previous version will be displayed
* Versioning does store multiple copies of the same file. 
```
So in the example of taking a 1MB file, and uploading it. Currently your storage usage would be 1MB. Now if you update the file with small tweeks, so that content changes, but the size remains the same, and upload it. With the version tab on hide, you will see only the single updated file, however if you select show on the slider, you will see that both the original 1MB file exists as well as the updated 1MB file, so your total S3 usage is now 2MB not 1MB
```
* Versioning does NOT support de-duplication or any similar technology currently
* For Cross Region Replication (CRR), as long as versioning is enabled, clicking on the tab will now give you the ability to suspend versioning, and enable cross region replication
* Cross Region Replication (CRR) has to be enabled on both the source and destination buckets in the selected regions
* Destination bucket must be created and again globally unique (can be created right from the versioning tab, in the CRR configuration section via button)
* You have the ability to select a separate storage class for any Cross Region Replication destination bucket
CRR does NOT replicate existing objects, only future objects meaning that only objects stored post turning the feature on will be replicated
* Any object that already exists at the time of turning CRR on, will NOT be automatically replicated
* Versioning integrates with life-cycle management and also supports MFA delete capability. This will use MFA to provide additional security against object deletion

## Life-cycle Management:
* When clicking on Life-cycle, and adding a rule, a rule can be applied to either the entire bucket or a single 'folder' in a bucket
* Rules can be set to move objects to either separate storage tiers or delete them all together
* Can be applied to current version and previous versions
* If multiple actions are selected for example transition from STD to IA storage 30 days after upload, and then Archive 60 days after upload is also selected, once an object is uploaded, 30 days later the object will be moved to IA storage. 30 days after that the object will be moved to glacier.
* Calculates based on **UPLOAD date not Action data**
* Transition from STD to IA storage class requires MINIMUM of 30 days. You can not select or set any data range less than 30 days
* Archive to Glacier can be set at a minimum of 1 day If STD->IA is NOT set
* If STD->IA IS set, then you will have to wait a minimum of 60 days to archive the object because the minimum for STD->IA is 30 days, and the transition to glacier then takes an additional 30 days
* When you enable versioning, there will be 2 sections in life-cycle management tab. 1 for the current version of an object, and another for previous versions
* Minimum file size for IA storage is 128K for an object
* Can set policy to permanently delete an object after a given time frame
* If versioning is enabled, then the object must be set to expire, before it can be permanently deleted
Can not move objects to Reduced Redundancy using life-cycle policies


## S3 Transfer Acceleration:
* Utilizes the CloudFront Edge Network to accelerate your uploads to S3
* Instead of uploading directly to your S3 bucket, you can use a distinct URL to upload directly to an edge location which will then transfer the file to S3
* There is a test utility available that will test uploading direct to S3 vs through Transfer Acceleration, which will show the upload speed from different global locations
* Turning on and using Transfer Acceleration will incur an additional fee

## 2 types of encryption available:
### In transit:
**Uses SSL/TLS to encrypt the transfer of the object**
* At Rest (AES 256):
    * Server Side: S3 Manged Keys (SSE-S3)
    * Server Side: AWS Key Management Service, Managed Keys (SSE-KMS)
    * Server Side: Encryption with Customer provided Keys (SSE-C)
*   Client Side Encryption
    * Pricing (What your charged for when using S3):
* Storage used
* Number of Requests
* Data Transfer


## S3 For DNS FailOver
* By using failover routing policy in a Route 53 record set, S3 bucket can be used as a failover endpoint.
* This can provide an extremely reliable backup solution if your primary endpoint fails.
* And even though S3 should only be used for static web hosting, It gives you the opportunity to provide your users with some type of information until the primary endpoint isworking again
* An S3 bucket can also be used as primary endpoint, if you just want to host a simple static site.

**Note: For DNS record to use an S3 bucket as an endpoint, bucket name MUST be the same as the domain name.

##Default Limi
 |Resource or Operation	|Default Limit
 |--|
|Buckets per account|	100
|Largest files size you can transfer with PUT request|	5GB
|Minimum file size|	0 byte
|Maximum file size|	5 TB